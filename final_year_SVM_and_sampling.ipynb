{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwI1LmBxAfQzdtsjUqx5zo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshvinVignesh/Final_year/blob/main/final_year_SVM_and_sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTJDCOJFlcmz",
        "outputId": "e78f9681-4cfd-4b26-ec9d-eef63d369b20",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deap) (1.26.4)\n",
            "Downloading deap-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deap\n",
            "Successfully installed deap-1.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jWu73F7Qz5Q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import classification_report , f1_score\n",
        "from sklearn.model_selection import StratifiedKFold , train_test_split ,GridSearchCV,cross_validate\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "# from imblearn.pipeline import Pipeline\n",
        "#from deap import base, creator, tools, algorithms\n",
        "import random"
      ],
      "metadata": {
        "id": "CkLv47j_RbSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"fyp_data.csv\")"
      ],
      "metadata": {
        "id": "D1xWJOXTRDft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[\"clean_text\"]\n",
        "y = df[['Acting', 'direction', 'Music',  'Genre', 'excitement','ovr_sent']] # Use a list of column names to select multiple columns"
      ],
      "metadata": {
        "id": "w7zKDMAXlpbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C_RANGE = [0.1, 1, 10, 100]\n",
        "KERNEL_RANGE = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "GAMMA_RANGE = ['scale', 'auto', 0.1, 1, 10]\n",
        "DEGREE_RANGE = [2, 3, 4, 5]  # Only for 'poly' kernel"
      ],
      "metadata": {
        "id": "x_l60S4Lj-Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_mutation(individual, indpb):\n",
        "    for i in range(len(individual)):\n",
        "        if random.random() < indpb:\n",
        "            if i == 0:  # C\n",
        "                individual[i] = random.choice(C_RANGE)\n",
        "            elif i == 1:  # kernel\n",
        "                individual[i] = random.choice(KERNEL_RANGE)\n",
        "            elif i == 2:  # gamma\n",
        "                individual[i] = random.choice(GAMMA_RANGE)\n",
        "            elif i == 3:  # degree (only if kernel is 'poly')\n",
        "                if individual[1] == 'poly':\n",
        "                    individual[i] = random.choice(DEGREE_RANGE)\n",
        "    return individual,"
      ],
      "metadata": {
        "id": "YI8jB_KIkh_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(X, y_df):\n",
        "    # Convert text to TF-IDF features\n",
        "    # Handle missing values by replacing them with an empty string\n",
        "    X = X.fillna('')\n",
        "    vectorizer = TfidfVectorizer(max_features=1000)\n",
        "    X_tfidf = vectorizer.fit_transform(X)\n",
        "\n",
        "    # Prepare label encoders for each target\n",
        "    label_encoders = {}\n",
        "    y_encoded = pd.DataFrame()\n",
        "\n",
        "    # Encode each target column\n",
        "    for column in y_df.columns:\n",
        "        le = LabelEncoder()\n",
        "        y_encoded[column] = le.fit_transform(y_df[column].astype(str))\n",
        "        label_encoders[column] = le\n",
        "\n",
        "    return X_tfidf, y_encoded, label_encoders\n",
        "\n",
        "def custom_f1_score(y_true, y_pred):\n",
        "    return f1_score(y_true, y_pred, average='micro')"
      ],
      "metadata": {
        "id": "FLJEV_HAkrhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)"
      ],
      "metadata": {
        "id": "rt0Bbc7pkvyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_toolbox(X, y_column):\n",
        "    toolbox = base.Toolbox()\n",
        "\n",
        "    # Define genes\n",
        "    toolbox.register(\"C\", random.choice, C_RANGE)\n",
        "    toolbox.register(\"kernel\", random.choice, KERNEL_RANGE)\n",
        "    toolbox.register(\"gamma\", random.choice, GAMMA_RANGE)\n",
        "    toolbox.register(\"degree\", random.choice, DEGREE_RANGE)\n",
        "\n",
        "    # Create individual and population\n",
        "    # Register the hyperparameters as attributes within the toolbox\n",
        "    toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "                     (toolbox.C, toolbox.kernel, toolbox.gamma, toolbox.degree), n=1)\n",
        "\n",
        "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "    # Define evaluation function\n",
        "    def evaluate(individual):\n",
        "      try:\n",
        "          svc = SVC(\n",
        "              C=individual[0],\n",
        "              kernel=individual[1],\n",
        "              gamma=individual[2],\n",
        "              degree=individual[3] if individual[1] == 'poly' else 3,  # Default degree if not 'poly'\n",
        "              random_state=42\n",
        "          )\n",
        "          scores = cross_val_score(svc, X, y_column, cv=3, scoring='f1_weighted')\n",
        "          return scores.mean(),\n",
        "      except Exception as e:\n",
        "          print(f\"Error with parameters: {individual}\")\n",
        "          print(f\"Error message: {str(e)}\")\n",
        "          return 0.0,\n",
        "\n",
        "    toolbox.register(\"evaluate\", evaluate)\n",
        "\n",
        "    # Genetic operators\n",
        "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "    toolbox.register(\"mutate\", custom_mutation, indpb=0.2)\n",
        "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "    return toolbox"
      ],
      "metadata": {
        "id": "RhVg5iUEk1A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_genetic_optimization(X, y_column, population_size=50, generations=50):\n",
        "    toolbox = create_toolbox(X, y_column)\n",
        "\n",
        "    # Create initial population\n",
        "    population = toolbox.population(n=population_size)\n",
        "\n",
        "    # Statistics setup\n",
        "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "    stats.register(\"avg\", np.mean)\n",
        "    stats.register(\"std\", np.std)\n",
        "    stats.register(\"min\", np.min)\n",
        "    stats.register(\"max\", np.max)\n",
        "\n",
        "    # Run the algorithm\n",
        "    final_pop, logbook = algorithms.eaSimple(population, toolbox,\n",
        "                                           cxpb=0.7,\n",
        "                                           mutpb=0.2,\n",
        "                                           ngen=generations,\n",
        "                                           stats=stats,\n",
        "                                           verbose=True)\n",
        "\n",
        "    # Get best solution\n",
        "    best_solution = tools.selBest(final_pop, k=1)[0]\n",
        "\n",
        "    # Convert to dictionary of parameters\n",
        "    best_params = {\n",
        "        'C': best_solution[0],\n",
        "        'kernel': best_solution[1],\n",
        "        'gamma': best_solution[2],\n",
        "        'degree': best_solution[3] if best_solution[1] == 'poly' else 3\n",
        "    }\n",
        "\n",
        "    return best_params, logbook"
      ],
      "metadata": {
        "id": "2AUmIx8YlHTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_all_targets(X, y_df, population_size=50, generations=5):\n",
        "    best_params_per_target = {}\n",
        "    models = {}\n",
        "\n",
        "    for column in y_df.columns:\n",
        "        print(f\"\\nOptimizing for target: {column}\")\n",
        "        best_params, logbook = run_genetic_optimization(X, y_df[column],\n",
        "                                                      population_size=population_size,\n",
        "                                                      generations=generations)\n",
        "\n",
        "        best_params_per_target[column] = best_params\n",
        "\n",
        "        # Train final model with best parameters\n",
        "        model = SVC(**best_params, random_state=42)\n",
        "        model.fit(X, y_df[column])\n",
        "        models[column] = model\n",
        "\n",
        "        print(f\"\\nBest parameters for {column}:\")\n",
        "        for param, value in best_params.items():\n",
        "            print(f\"{param}: {value}\")\n",
        "\n",
        "    return best_params_per_target, models"
      ],
      "metadata": {
        "id": "RyZKFDHfmOj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_processed, y_encoded, label_encoders = prepare_data(\n",
        "    df[\"clean_text\"],\n",
        "    y\n",
        ")"
      ],
      "metadata": {
        "id": "qJTlu3WulQxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params_per_target, trained_models = optimize_all_targets(X_processed, y_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMlxk9gelSyS",
        "outputId": "71969b02-af6c-4b73-d3a8-d043ff6305d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimizing for target: Acting\n",
            "gen\tnevals\tavg     \tstd      \tmin     \tmax     \n",
            "0  \t50    \t0.698794\t0.0316926\t0.646345\t0.734983\n",
            "1  \t42    \t0.7164  \t0.0238985\t0.646345\t0.734983\n",
            "2  \t40    \t0.726797\t0.014168 \t0.659229\t0.734983\n",
            "3  \t35    \t0.7289  \t0.00965129\t0.698962\t0.740314\n",
            "4  \t40    \t0.730089\t0.0182152 \t0.659229\t0.740314\n",
            "5  \t40    \t0.733448\t0.00831028\t0.698962\t0.740314\n",
            "\n",
            "Best parameters for Acting:\n",
            "C: 100\n",
            "kernel: rbf\n",
            "gamma: 0.1\n",
            "degree: 3\n",
            "\n",
            "Optimizing for target: direction\n",
            "gen\tnevals\tavg     \tstd      \tmin     \tmax     \n",
            "0  \t50    \t0.735588\t0.0263466\t0.708418\t0.775701\n",
            "1  \t41    \t0.757355\t0.0172131\t0.708418\t0.775701\n",
            "2  \t35    \t0.7646  \t0.0140745\t0.708418\t0.775701\n",
            "3  \t36    \t0.764472\t0.014822 \t0.708658\t0.775701\n",
            "4  \t39    \t0.762424\t0.0155674\t0.710915\t0.775701\n",
            "5  \t33    \t0.768676\t0.0113324\t0.710915\t0.775701\n",
            "\n",
            "Best parameters for direction:\n",
            "C: 100\n",
            "kernel: rbf\n",
            "gamma: 1\n",
            "degree: 3\n",
            "\n",
            "Optimizing for target: Music\n",
            "gen\tnevals\tavg     \tstd      \tmin     \tmax     \n",
            "0  \t50    \t0.878722\t0.0459482\t0.817211\t0.937152\n",
            "1  \t38    \t0.900282\t0.0385586\t0.817211\t0.932494\n",
            "2  \t42    \t0.92221 \t0.0226105\t0.817211\t0.932494\n",
            "3  \t44    \t0.928152\t0.0163802\t0.838154\t0.932494\n",
            "4  \t42    \t0.931301\t0.00433787\t0.912682\t0.932494\n",
            "5  \t34    \t0.930896\t0.00505357\t0.912682\t0.932494\n",
            "\n",
            "Best parameters for Music:\n",
            "C: 1\n",
            "kernel: linear\n",
            "gamma: 0.1\n",
            "degree: 3\n",
            "\n",
            "Optimizing for target: Genre\n",
            "gen\tnevals\tavg     \tstd       \tmin     \tmax     \n",
            "0  \t50    \t0.927096\t0.00584115\t0.910372\t0.941642\n",
            "1  \t43    \t0.931401\t0.00620955\t0.921548\t0.941642\n",
            "2  \t43    \t0.934625\t0.00732555\t0.910277\t0.941642\n",
            "3  \t40    \t0.938133\t0.00570168\t0.924848\t0.941642\n",
            "4  \t42    \t0.937427\t0.0067121 \t0.924848\t0.941642\n",
            "5  \t36    \t0.941172\t0.0023423 \t0.926474\t0.941642\n",
            "\n",
            "Best parameters for Genre:\n",
            "C: 10\n",
            "kernel: rbf\n",
            "gamma: 0.1\n",
            "degree: 3\n",
            "\n",
            "Optimizing for target: excitement\n",
            "gen\tnevals\tavg     \tstd      \tmin     \tmax     \n",
            "0  \t50    \t0.510754\t0.0744921\t0.413309\t0.630444\n",
            "1  \t34    \t0.572731\t0.0582234\t0.413309\t0.630444\n",
            "2  \t40    \t0.586342\t0.0485136\t0.413309\t0.631431\n",
            "3  \t39    \t0.607104\t0.0407886\t0.413309\t0.631431\n",
            "4  \t41    \t0.619985\t0.0344449\t0.425212\t0.631431\n",
            "5  \t33    \t0.610555\t0.0532592\t0.413309\t0.631431\n",
            "\n",
            "Best parameters for excitement:\n",
            "C: 10\n",
            "kernel: rbf\n",
            "gamma: 0.1\n",
            "degree: 3\n",
            "\n",
            "Optimizing for target: ovr_sent\n",
            "gen\tnevals\tavg     \tstd     \tmin     \tmax     \n",
            "0  \t50    \t0.522461\t0.115374\t0.347751\t0.649033\n",
            "1  \t41    \t0.580546\t0.0834383\t0.347751\t0.649033\n",
            "2  \t36    \t0.619439\t0.0487117\t0.347751\t0.649033\n",
            "3  \t34    \t0.626005\t0.0571615\t0.347751\t0.649033\n",
            "4  \t40    \t0.641469\t0.0388492\t0.371687\t0.649033\n",
            "5  \t38    \t0.641394\t0.0389908\t0.372117\t0.649033\n",
            "\n",
            "Best parameters for ovr_sent:\n",
            "C: 10\n",
            "kernel: rbf\n",
            "gamma: scale\n",
            "degree: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(df, aspect_column):\n",
        "    \"\"\"Prepare data for a specific aspect\"\"\"\n",
        "    # Encode text to numerical values if needed\n",
        "    # le = LabelEncoder()\n",
        "    # Changed to return a DataFrame instead of a Series\n",
        "    X = df[['clean_text']]\n",
        "    y = df[aspect_column]\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "Tn1vmUz2RU8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate_model(X, y,aspect, sampling_strategy='none'):\n",
        "    \"\"\"Train and evaluate SVM model with different sampling techniques\"\"\"\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    vectorizer = TfidfVectorizer(max_features=5000,\n",
        "                                ngram_range=(1, 2),\n",
        "                                min_df=2,\n",
        "                                max_df=0.95)\n",
        "\n",
        "    # Transform features and encode labels to categorical\n",
        "    X_tfidf = vectorizer.fit_transform(X['clean_text'])\n",
        "\n",
        "    # Encode target labels to categorical for CategoricalNB\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(y)\n",
        "\n",
        "    # Print the mapping between original and encoded labels\n",
        "    print(\"Label Mapping:\")\n",
        "    for original_label, encoded_label in zip(le.classes_, le.transform(le.classes_)):\n",
        "        print(f\"{original_label} -> {encoded_label}\")\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_tfidf, y_encoded)):  # Split using encoded labels\n",
        "        X_train, X_val = X_tfidf[train_idx], X_tfidf[val_idx]\n",
        "        y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]  # Use encoded labels\n",
        "\n",
        "        # Apply sampling strategy\n",
        "        if sampling_strategy == 'oversample':\n",
        "            sampler = SMOTE(random_state=42)\n",
        "            X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
        "        elif sampling_strategy == 'undersample':\n",
        "            sampler = RandomUnderSampler(random_state=42)\n",
        "            X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
        "\n",
        "        # Convert X_train and X_val to dense arrays\n",
        "        # X_train = X_train.toarray()\n",
        "        # X_val = X_val.toarray()\n",
        "\n",
        "        if aspect == \"acting\":\n",
        "          model =   SVC(random_state=42, C=100 ,kernel=\"rbf\" , gamma=0.1 ,degree=3)\n",
        "        elif aspect == \"direction\":\n",
        "          model =   SVC(random_state=42, C=10 ,kernel=\"rbf\" , gamma=0.1 ,degree=3)\n",
        "        elif aspect == \"music\":\n",
        "          model =   SVC(random_state=42, C=1 ,kernel=\"linear\" , gamma=0.1 ,degree=3)\n",
        "        elif aspect == \"genre\":\n",
        "          model =   SVC(random_state=42, C=1 ,kernel=\"sigmoid\" , gamma=\"scale\" ,degree=3)\n",
        "        elif aspect == \"excitement\":\n",
        "          model =   SVC(random_state=42, C=10 ,kernel=\"rbf\" , gamma=0.1 ,degree=3)\n",
        "        elif aspect == \"ovr_sent\":\n",
        "          model =   SVC(random_state=42, C=10 ,kernel=\"rbf\" , gamma=\"scale\" ,degree=3)\n",
        "        else:\n",
        "          raise ValueError(f\"Unknown aspect: {aspect}\")\n",
        "\n",
        "        # Change CategoricalNB to MultinomialNB to handle TF-IDF features\n",
        "        # model = CategoricalNB()\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate\n",
        "        y_pred = model.predict(X_val)\n",
        "        score = accuracy_score(y_val, y_pred)  # Use encoded labels for evaluation\n",
        "        scores.append(score)\n",
        "\n",
        "        print(f\"\\nFold {fold + 1} Results:\")\n",
        "        print(classification_report(y_val, y_pred))  # Use encoded labels for classification report\n",
        "\n",
        "    return np.mean(scores), np.std(scores)"
      ],
      "metadata": {
        "id": "Jmf8GOLJEHKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_all_aspects_undersample(df, aspects):\n",
        "    \"\"\"Analyze all aspects with different sampling techniques\"\"\"\n",
        "    results = {}\n",
        "    # sampling_techniques = ['none', 'oversample', 'undersample']\n",
        "    sampling_techniques = ['undersample']\n",
        "\n",
        "    for aspect in aspects:\n",
        "        print(f\"\\nAnalyzing aspect: {aspect}\")\n",
        "        X, y = prepare_data(df, aspect)\n",
        "\n",
        "        aspect_results = {}\n",
        "        for technique in sampling_techniques:\n",
        "            print(f\"\\nUsing {technique} sampling:\")\n",
        "            mean_score, std_score = train_evaluate_model(X, y, aspect.lower() ,technique)\n",
        "            aspect_results[technique] = {\n",
        "                'mean_accuracy': mean_score,\n",
        "                'std_accuracy': std_score\n",
        "            }\n",
        "            print(f\"Mean Accuracy: {mean_score:.4f} (±{std_score:.4f})\")\n",
        "\n",
        "        results[aspect] = aspect_results\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "nz-EE5KCROAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aspects = ['Acting', 'direction', 'Music',  'Genre', 'excitement','ovr_sent']\n",
        "results = analyze_all_aspects_undersample(df, aspects)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "lDfsYe0PSABA",
        "outputId": "d31c2a3c-b231-4e22-d833-b6dd41f242cb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'analyze_all_aspects_undersample' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-17a62e1294f6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0maspects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Acting'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'direction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Music'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ovr_sent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_all_aspects_undersample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'analyze_all_aspects_undersample' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_all_aspects_oversample(df, aspects):\n",
        "    \"\"\"Analyze all aspects with different sampling techniques\"\"\"\n",
        "    results = {}\n",
        "    # sampling_techniques = ['none', 'oversample', 'undersample']\n",
        "    sampling_techniques = ['oversample']\n",
        "\n",
        "    for aspect in aspects:\n",
        "        print(f\"\\nAnalyzing aspect: {aspect}\")\n",
        "        X, y = prepare_data(df, aspect)\n",
        "\n",
        "        aspect_results = {}\n",
        "        for technique in sampling_techniques:\n",
        "            print(f\"\\nUsing {technique} sampling:\")\n",
        "            mean_score, std_score = train_evaluate_model(X, y,aspect.lower(), technique)\n",
        "            aspect_results[technique] = {\n",
        "                'mean_accuracy': mean_score,\n",
        "                'std_accuracy': std_score\n",
        "            }\n",
        "            print(f\"Mean Accuracy: {mean_score:.4f} (±{std_score:.4f})\")\n",
        "\n",
        "        results[aspect] = aspect_results\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "ptT-XtNX1aOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aspects = ['Acting', 'direction', 'Music',  'Genre', 'excitement','ovr_sent']\n",
        "results = analyze_all_aspects_oversample(df, aspects)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGZB-Kyr1khz",
        "outputId": "504fb541-8b6e-4b9e-b94a-32dc377db8b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analyzing aspect: Acting\n",
            "\n",
            "Using oversample sampling:\n",
            "Label Mapping:\n",
            "-1 -> 0\n",
            "0 -> 1\n",
            "1 -> 2\n",
            "\n",
            "Fold 1 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.15      0.17        34\n",
            "           1       0.88      0.92      0.90       770\n",
            "           2       0.68      0.61      0.64       221\n",
            "\n",
            "    accuracy                           0.82      1025\n",
            "   macro avg       0.58      0.56      0.57      1025\n",
            "weighted avg       0.81      0.82      0.82      1025\n",
            "\n",
            "\n",
            "Fold 2 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      0.12      0.13        33\n",
            "           1       0.88      0.90      0.89       769\n",
            "           2       0.65      0.60      0.62       222\n",
            "\n",
            "    accuracy                           0.81      1024\n",
            "   macro avg       0.55      0.54      0.55      1024\n",
            "weighted avg       0.80      0.81      0.81      1024\n",
            "\n",
            "\n",
            "Fold 3 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.21      0.20        33\n",
            "           1       0.88      0.88      0.88       769\n",
            "           2       0.65      0.64      0.64       222\n",
            "\n",
            "    accuracy                           0.81      1024\n",
            "   macro avg       0.57      0.58      0.58      1024\n",
            "weighted avg       0.81      0.81      0.81      1024\n",
            "\n",
            "\n",
            "Fold 4 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.12      0.16        33\n",
            "           1       0.87      0.90      0.89       769\n",
            "           2       0.64      0.61      0.63       222\n",
            "\n",
            "    accuracy                           0.81      1024\n",
            "   macro avg       0.58      0.54      0.56      1024\n",
            "weighted avg       0.80      0.81      0.81      1024\n",
            "\n",
            "\n",
            "Fold 5 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      0.21      0.19        34\n",
            "           1       0.88      0.90      0.89       769\n",
            "           2       0.68      0.62      0.65       221\n",
            "\n",
            "    accuracy                           0.82      1024\n",
            "   macro avg       0.58      0.58      0.58      1024\n",
            "weighted avg       0.82      0.82      0.82      1024\n",
            "\n",
            "Mean Accuracy: 0.8143 (±0.0058)\n",
            "\n",
            "Analyzing aspect: direction\n",
            "\n",
            "Using oversample sampling:\n",
            "Label Mapping:\n",
            "-1 -> 0\n",
            "0 -> 1\n",
            "1 -> 2\n",
            "\n",
            "Fold 1 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.41      0.44       139\n",
            "           1       0.89      0.92      0.90       824\n",
            "           2       0.56      0.52      0.54        62\n",
            "\n",
            "    accuracy                           0.82      1025\n",
            "   macro avg       0.64      0.61      0.63      1025\n",
            "weighted avg       0.81      0.82      0.82      1025\n",
            "\n",
            "\n",
            "Fold 2 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.48      0.47       138\n",
            "           1       0.89      0.90      0.89       824\n",
            "           2       0.53      0.45      0.49        62\n",
            "\n",
            "    accuracy                           0.81      1024\n",
            "   macro avg       0.63      0.61      0.62      1024\n",
            "weighted avg       0.81      0.81      0.81      1024\n",
            "\n",
            "\n",
            "Fold 3 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.47      0.52       139\n",
            "           1       0.88      0.94      0.91       823\n",
            "           2       0.51      0.32      0.40        62\n",
            "\n",
            "    accuracy                           0.84      1024\n",
            "   macro avg       0.66      0.58      0.61      1024\n",
            "weighted avg       0.82      0.84      0.83      1024\n",
            "\n",
            "\n",
            "Fold 4 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.42      0.44       139\n",
            "           1       0.89      0.92      0.90       823\n",
            "           2       0.49      0.34      0.40        62\n",
            "\n",
            "    accuracy                           0.82      1024\n",
            "   macro avg       0.61      0.56      0.58      1024\n",
            "weighted avg       0.80      0.82      0.81      1024\n",
            "\n",
            "\n",
            "Fold 5 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.44      0.48       139\n",
            "           1       0.88      0.93      0.91       823\n",
            "           2       0.49      0.34      0.40        62\n",
            "\n",
            "    accuracy                           0.83      1024\n",
            "   macro avg       0.63      0.57      0.60      1024\n",
            "weighted avg       0.81      0.83      0.82      1024\n",
            "\n",
            "Mean Accuracy: 0.8243 (±0.0092)\n",
            "\n",
            "Analyzing aspect: Music\n",
            "\n",
            "Using oversample sampling:\n",
            "Label Mapping:\n",
            "-1 -> 0\n",
            "0 -> 1\n",
            "1 -> 2\n",
            "\n",
            "Fold 1 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.32      0.42        22\n",
            "           1       0.98      0.97      0.97       897\n",
            "           2       0.72      0.88      0.79       106\n",
            "\n",
            "    accuracy                           0.94      1025\n",
            "   macro avg       0.78      0.72      0.73      1025\n",
            "weighted avg       0.95      0.94      0.94      1025\n",
            "\n",
            "\n",
            "Fold 2 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.29      0.39        21\n",
            "           1       0.98      0.97      0.97       897\n",
            "           2       0.68      0.81      0.74       106\n",
            "\n",
            "    accuracy                           0.94      1024\n",
            "   macro avg       0.75      0.69      0.70      1024\n",
            "weighted avg       0.94      0.94      0.94      1024\n",
            "\n",
            "\n",
            "Fold 3 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.29      0.32        21\n",
            "           1       0.98      0.98      0.98       897\n",
            "           2       0.74      0.77      0.76       106\n",
            "\n",
            "    accuracy                           0.94      1024\n",
            "   macro avg       0.69      0.68      0.68      1024\n",
            "weighted avg       0.94      0.94      0.94      1024\n",
            "\n",
            "\n",
            "Fold 4 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.29      0.38        21\n",
            "           1       0.97      0.97      0.97       897\n",
            "           2       0.75      0.82      0.78       106\n",
            "\n",
            "    accuracy                           0.94      1024\n",
            "   macro avg       0.76      0.69      0.71      1024\n",
            "weighted avg       0.94      0.94      0.94      1024\n",
            "\n",
            "\n",
            "Fold 5 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.23      0.31        22\n",
            "           1       0.97      0.98      0.97       896\n",
            "           2       0.74      0.80      0.77       106\n",
            "\n",
            "    accuracy                           0.94      1024\n",
            "   macro avg       0.74      0.67      0.69      1024\n",
            "weighted avg       0.94      0.94      0.94      1024\n",
            "\n",
            "Mean Accuracy: 0.9416 (±0.0029)\n",
            "\n",
            "Analyzing aspect: Genre\n",
            "\n",
            "Using oversample sampling:\n",
            "Label Mapping:\n",
            "-1 -> 0\n",
            "0 -> 1\n",
            "1 -> 2\n",
            "\n",
            "Fold 1 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.04      0.10      0.06        10\n",
            "           1       0.97      0.94      0.95       975\n",
            "           2       0.23      0.35      0.28        40\n",
            "\n",
            "    accuracy                           0.91      1025\n",
            "   macro avg       0.41      0.46      0.43      1025\n",
            "weighted avg       0.93      0.91      0.92      1025\n",
            "\n",
            "\n",
            "Fold 2 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.08      0.27      0.12        11\n",
            "           1       0.98      0.92      0.95       974\n",
            "           2       0.23      0.41      0.29        39\n",
            "\n",
            "    accuracy                           0.89      1024\n",
            "   macro avg       0.43      0.53      0.45      1024\n",
            "weighted avg       0.94      0.89      0.91      1024\n",
            "\n",
            "\n",
            "Fold 3 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        11\n",
            "           1       0.97      0.94      0.95       974\n",
            "           2       0.30      0.41      0.35        39\n",
            "\n",
            "    accuracy                           0.91      1024\n",
            "   macro avg       0.42      0.45      0.43      1024\n",
            "weighted avg       0.93      0.91      0.92      1024\n",
            "\n",
            "\n",
            "Fold 4 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        11\n",
            "           1       0.96      0.92      0.94       974\n",
            "           2       0.27      0.36      0.31        39\n",
            "\n",
            "    accuracy                           0.89      1024\n",
            "   macro avg       0.41      0.43      0.42      1024\n",
            "weighted avg       0.93      0.89      0.91      1024\n",
            "\n",
            "\n",
            "Fold 5 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.07      0.30      0.12        10\n",
            "           1       0.97      0.93      0.95       974\n",
            "           2       0.33      0.38      0.35        40\n",
            "\n",
            "    accuracy                           0.91      1024\n",
            "   macro avg       0.46      0.54      0.47      1024\n",
            "weighted avg       0.94      0.91      0.92      1024\n",
            "\n",
            "Mean Accuracy: 0.9004 (±0.0085)\n",
            "\n",
            "Analyzing aspect: excitement\n",
            "\n",
            "Using oversample sampling:\n",
            "Label Mapping:\n",
            "-1 -> 0\n",
            "0 -> 1\n",
            "1 -> 2\n",
            "\n",
            "Fold 1 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.39      0.42       152\n",
            "           1       0.71      0.77      0.74       583\n",
            "           2       0.63      0.57      0.60       290\n",
            "\n",
            "    accuracy                           0.66      1025\n",
            "   macro avg       0.60      0.58      0.59      1025\n",
            "weighted avg       0.65      0.66      0.65      1025\n",
            "\n",
            "\n",
            "Fold 2 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.50      0.52       152\n",
            "           1       0.73      0.77      0.75       583\n",
            "           2       0.62      0.58      0.60       289\n",
            "\n",
            "    accuracy                           0.67      1024\n",
            "   macro avg       0.63      0.62      0.62      1024\n",
            "weighted avg       0.67      0.67      0.67      1024\n",
            "\n",
            "\n",
            "Fold 3 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.48      0.48       151\n",
            "           1       0.71      0.76      0.74       583\n",
            "           2       0.67      0.58      0.62       290\n",
            "\n",
            "    accuracy                           0.67      1024\n",
            "   macro avg       0.62      0.61      0.61      1024\n",
            "weighted avg       0.67      0.67      0.67      1024\n",
            "\n",
            "\n",
            "Fold 4 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.45      0.48       152\n",
            "           1       0.72      0.80      0.76       582\n",
            "           2       0.67      0.58      0.62       290\n",
            "\n",
            "    accuracy                           0.68      1024\n",
            "   macro avg       0.64      0.61      0.62      1024\n",
            "weighted avg       0.68      0.68      0.68      1024\n",
            "\n",
            "\n",
            "Fold 5 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.47      0.48       152\n",
            "           1       0.73      0.79      0.76       582\n",
            "           2       0.70      0.62      0.66       290\n",
            "\n",
            "    accuracy                           0.69      1024\n",
            "   macro avg       0.65      0.63      0.63      1024\n",
            "weighted avg       0.69      0.69      0.69      1024\n",
            "\n",
            "Mean Accuracy: 0.6751 (±0.0121)\n",
            "\n",
            "Analyzing aspect: ovr_sent\n",
            "\n",
            "Using oversample sampling:\n",
            "Label Mapping:\n",
            "-1 -> 0\n",
            "0 -> 1\n",
            "1 -> 2\n",
            "\n",
            "Fold 1 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.68      0.67       344\n",
            "           1       0.34      0.14      0.20       152\n",
            "           2       0.73      0.84      0.78       529\n",
            "\n",
            "    accuracy                           0.68      1025\n",
            "   macro avg       0.58      0.55      0.55      1025\n",
            "weighted avg       0.65      0.68      0.66      1025\n",
            "\n",
            "\n",
            "Fold 2 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.73      0.72       343\n",
            "           1       0.57      0.23      0.33       152\n",
            "           2       0.75      0.85      0.80       529\n",
            "\n",
            "    accuracy                           0.72      1024\n",
            "   macro avg       0.67      0.61      0.61      1024\n",
            "weighted avg       0.71      0.72      0.70      1024\n",
            "\n",
            "\n",
            "Fold 3 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.71      0.72       343\n",
            "           1       0.46      0.24      0.31       153\n",
            "           2       0.75      0.87      0.81       528\n",
            "\n",
            "    accuracy                           0.72      1024\n",
            "   macro avg       0.65      0.60      0.61      1024\n",
            "weighted avg       0.70      0.72      0.70      1024\n",
            "\n",
            "\n",
            "Fold 4 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.72      0.68       344\n",
            "           1       0.43      0.19      0.26       152\n",
            "           2       0.75      0.80      0.77       528\n",
            "\n",
            "    accuracy                           0.68      1024\n",
            "   macro avg       0.61      0.57      0.57      1024\n",
            "weighted avg       0.66      0.68      0.66      1024\n",
            "\n",
            "\n",
            "Fold 5 Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.75      0.72       344\n",
            "           1       0.44      0.20      0.27       152\n",
            "           2       0.75      0.83      0.79       528\n",
            "\n",
            "    accuracy                           0.71      1024\n",
            "   macro avg       0.63      0.59      0.59      1024\n",
            "weighted avg       0.69      0.71      0.69      1024\n",
            "\n",
            "Mean Accuracy: 0.7028 (±0.0173)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aspects = ['Acting', 'direction', 'Music','ovr_sent']"
      ],
      "metadata": {
        "id": "LCcn9h1Y7kxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_final_models_grid_search(df, aspects):\n",
        "    \"\"\"\n",
        "    For each aspect, perform a grid search to find the best SVC parameters using a pipeline.\n",
        "    Uses an 80/20 train-test split, prints training and test accuracy and classification reports,\n",
        "    and returns the best models along with their label encoders.\n",
        "    \"\"\"\n",
        "    best_models = {}\n",
        "    train_reports = {}\n",
        "    test_reports = {}\n",
        "\n",
        "    # Define a parameter grid for the SVC inside a pipeline\n",
        "    param_grid = {\n",
        "        'clf__kernel': ['linear', 'rbf', 'sigmoid'],\n",
        "        'clf__C': [1,10],\n",
        "        'clf__gamma': [0.01, 0.1, 1]\n",
        "    }\n",
        "\n",
        "    for aspect in aspects:\n",
        "        print(f\"\\n=== Processing aspect: {aspect} ===\")\n",
        "        X, y = prepare_data(df, aspect)\n",
        "        # Encode target labels to numerical values\n",
        "        le = LabelEncoder()\n",
        "        y_encoded = le.fit_transform(y)\n",
        "\n",
        "        # Split data into training and testing sets (80/20 split)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        "        )\n",
        "\n",
        "        # Create a pipeline: first vectorize text, then classify with SVC\n",
        "        pipeline = Pipeline([\n",
        "            ('tfidf', TfidfVectorizer(max_features=5000,\n",
        "                                      ngram_range=(1, 2),\n",
        "                                      min_df=2,\n",
        "                                      max_df=0.95)),\n",
        "            ('clf', SVC(random_state=42))\n",
        "        ])\n",
        "\n",
        "        # Set up GridSearchCV with 5-fold cross-validation\n",
        "        cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        grid = GridSearchCV(pipeline, param_grid, cv=cv_strategy, scoring='accuracy', n_jobs=-1)\n",
        "        grid.fit(X_train['clean_text'], y_train)\n",
        "\n",
        "        print(f\"Best parameters for aspect '{aspect}': {grid.best_params_}\")\n",
        "\n",
        "        best_estimator = grid.best_estimator_\n",
        "\n",
        "        # Evaluate on training data\n",
        "        y_train_pred = best_estimator.predict(X_train['clean_text'])\n",
        "        train_acc = accuracy_score(y_train, y_train_pred)\n",
        "        print(\"Training Accuracy: {:.4f}\".format(train_acc))\n",
        "        train_report = classification_report(y_train, y_train_pred)\n",
        "        print(\"Training Classification Report:\\n\", train_report)\n",
        "\n",
        "        # Evaluate on test data\n",
        "        y_test_pred = best_estimator.predict(X_test['clean_text'])\n",
        "        test_acc = accuracy_score(y_test, y_test_pred)\n",
        "        print(\"Test Accuracy: {:.4f}\".format(test_acc))\n",
        "        test_report = classification_report(y_test, y_test_pred)\n",
        "        print(\"Test Classification Report:\\n\", test_report)\n",
        "\n",
        "        best_models[aspect.lower()] = {\n",
        "            \"model\": best_estimator,\n",
        "            \"label_encoder\": le\n",
        "        }\n",
        "        train_reports[aspect.lower()] = train_report\n",
        "        test_reports[aspect.lower()] = test_report\n",
        "\n",
        "    return best_models, train_reports, test_reports"
      ],
      "metadata": {
        "id": "23wYEX6O_cSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_all_aspects(sentence, final_models):\n",
        "    \"\"\"\n",
        "    Given a sentence, predict its sentiment for all aspects using the final trained models.\n",
        "    Returns a dictionary with aspect names as keys and predicted labels as values.\n",
        "    \"\"\"\n",
        "    predictions = {}\n",
        "    for aspect, model_info in final_models.items():\n",
        "        model = model_info['model']\n",
        "        le = model_info['label_encoder']\n",
        "        # The pipeline expects raw text\n",
        "        pred_encoded = model.predict([sentence])[0]\n",
        "        pred_label = le.inverse_transform([pred_encoded])[0]\n",
        "        predictions[aspect] = pred_label\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "4Kb4Ie3P_g3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models, train_reports, test_reports = train_final_models_grid_search(df, aspects)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmMQ2pHN_lcG",
        "outputId": "db82fc87-8639-451a-c5a6-15eea48a2225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing aspect: Acting ===\n",
            "Best parameters for aspect 'Acting': {'clf__C': 1, 'clf__gamma': 0.01, 'clf__kernel': 'linear'}\n",
            "Training Accuracy: 0.9158\n",
            "Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.21      0.35       132\n",
            "           1       0.91      0.99      0.95      2966\n",
            "           2       0.93      0.76      0.84       843\n",
            "\n",
            "    accuracy                           0.92      3941\n",
            "   macro avg       0.95      0.66      0.71      3941\n",
            "weighted avg       0.92      0.92      0.91      3941\n",
            "\n",
            "Test Accuracy: 0.8438\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.03      0.06        33\n",
            "           1       0.86      0.95      0.91       742\n",
            "           2       0.74      0.59      0.66       211\n",
            "\n",
            "    accuracy                           0.84       986\n",
            "   macro avg       0.87      0.52      0.54       986\n",
            "weighted avg       0.84      0.84      0.82       986\n",
            "\n",
            "\n",
            "=== Processing aspect: direction ===\n",
            "Best parameters for aspect 'direction': {'clf__C': 10, 'clf__gamma': 0.1, 'clf__kernel': 'rbf'}\n",
            "Training Accuracy: 0.9538\n",
            "Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.80      0.88       554\n",
            "           1       0.95      1.00      0.97      3145\n",
            "           2       0.97      0.75      0.85       242\n",
            "\n",
            "    accuracy                           0.95      3941\n",
            "   macro avg       0.96      0.85      0.90      3941\n",
            "weighted avg       0.95      0.95      0.95      3941\n",
            "\n",
            "Test Accuracy: 0.8327\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.34      0.42       138\n",
            "           1       0.87      0.96      0.91       787\n",
            "           2       0.65      0.36      0.46        61\n",
            "\n",
            "    accuracy                           0.83       986\n",
            "   macro avg       0.69      0.55      0.60       986\n",
            "weighted avg       0.81      0.83      0.81       986\n",
            "\n",
            "\n",
            "=== Processing aspect: Music ===\n",
            "Best parameters for aspect 'Music': {'clf__C': 10, 'clf__gamma': 0.1, 'clf__kernel': 'rbf'}\n",
            "Training Accuracy: 0.9878\n",
            "Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.87      0.93        86\n",
            "           1       0.99      1.00      0.99      3450\n",
            "           2       0.97      0.92      0.95       405\n",
            "\n",
            "    accuracy                           0.99      3941\n",
            "   macro avg       0.98      0.93      0.96      3941\n",
            "weighted avg       0.99      0.99      0.99      3941\n",
            "\n",
            "Test Accuracy: 0.9574\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.24      0.38        21\n",
            "           1       0.96      1.00      0.98       863\n",
            "           2       0.90      0.77      0.83       102\n",
            "\n",
            "    accuracy                           0.96       986\n",
            "   macro avg       0.95      0.67      0.73       986\n",
            "weighted avg       0.96      0.96      0.95       986\n",
            "\n",
            "\n",
            "=== Processing aspect: ovr_sent ===\n",
            "Best parameters for aspect 'ovr_sent': {'clf__C': 1, 'clf__gamma': 1, 'clf__kernel': 'sigmoid'}\n",
            "Training Accuracy: 0.8198\n",
            "Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.88      0.83      1355\n",
            "           1       0.92      0.29      0.44       565\n",
            "           2       0.83      0.93      0.88      2021\n",
            "\n",
            "    accuracy                           0.82      3941\n",
            "   macro avg       0.85      0.70      0.72      3941\n",
            "weighted avg       0.83      0.82      0.80      3941\n",
            "\n",
            "Test Accuracy: 0.7059\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.76      0.70       339\n",
            "           1       0.71      0.14      0.24       141\n",
            "           2       0.74      0.83      0.78       506\n",
            "\n",
            "    accuracy                           0.71       986\n",
            "   macro avg       0.70      0.58      0.57       986\n",
            "weighted avg       0.71      0.71      0.68       986\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# # Save the models to a pickle file\n",
        "# with open('sentiment_models_SVM.pkl', 'wb') as f:\n",
        "#     pickle.dump(best_models, f)\n",
        "\n",
        "# Load the models from the pickle file\n",
        "with open('sentiment_models_SVM.pkl', 'rb') as f:\n",
        "    loaded_models = pickle.load(f)\n",
        "\n",
        "# Function to predict all aspects using the loaded models\n",
        "def predict_all_aspects_loaded(sentence, loaded_models):\n",
        "    predictions = {}\n",
        "    for aspect, model_info in loaded_models.items():\n",
        "        model = model_info['model']\n",
        "        le = model_info['label_encoder']\n",
        "        pred_encoded = model.predict([sentence])[0]\n",
        "        pred_label = le.inverse_transform([pred_encoded])[0]\n",
        "        predictions[aspect] = pred_label\n",
        "    return predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "pzRbVj6_AMUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage with a sample sentence\n",
        "sample_sentence = \"Yuvam bgm nalla potu irukaaru\"\n",
        "predictions = predict_all_aspects_loaded(sample_sentence, loaded_models)\n",
        "\n",
        "print(\"\\nPredictions for the sample sentence:\")\n",
        "for aspect, pred in predictions.items():\n",
        "    print(f\"{aspect.capitalize()}: {pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJKPEy4AC1RB",
        "outputId": "72654e5b-28ac-47d4-9e06-21b5cd602bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predictions for the sample sentence:\n",
            "Acting: 0\n",
            "Direction: 0\n",
            "Music: 1\n",
            "Ovr_sent: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence = \"superster nalla illa \"\n",
        "predictions = predict_all_aspects(sample_sentence, best_models)\n",
        "\n",
        "print(\"\\nPredictions for the sample sentence:\")\n",
        "for aspect, pred in predictions.items():\n",
        "    print(f\"{aspect.capitalize()}: {pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "En5Rmk2SCht4",
        "outputId": "f862c3b0-088c-4fba-bb75-a570635b82a7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models loaded from final_models_dl.pkl\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized data type: x=['superster nalla illa '] (of type <class 'list'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e05586d640c6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"superster nalla illa \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_all_aspects_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_sentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"final_models_dl.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nPredictions for the sample sentence:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3cfc12bdcef3>\u001b[0m in \u001b[0;36mpredict_all_aspects_from_file\u001b[0;34m(sentence, model_filename)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_encoder'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpred_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mpred_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_encoded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/__init__.py\u001b[0m in \u001b[0;36mget_data_adapter\u001b[0;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unrecognized data type: x={x} (of type {type(x)})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized data type: x=['superster nalla illa '] (of type <class 'list'>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_tokenizer(text):\n",
        "    return text.split()"
      ],
      "metadata": {
        "id": "XlI9OlacaRCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"train_data.csv\")\n",
        "test_df = pd.read_csv(\"test_data.csv\")\n",
        "def train_final_models_grid_search(train_df, test_df, aspects):\n",
        "    \"\"\"\n",
        "    For each aspect:\n",
        "    1. Perform grid search on the training data to find the best parameters.\n",
        "    2. Using the best parameters, perform 10-fold cross-validation,\n",
        "       returning both the average accuracy and the list of fold estimators.\n",
        "    3. Select the best estimator from CV (highest test score) and evaluate it on test data.\n",
        "    Returns the best models along with their label encoders and classification reports.\n",
        "    \"\"\"\n",
        "    best_models = {}\n",
        "    train_reports = {}\n",
        "    test_reports = {}\n",
        "\n",
        "    # Parameter grid for the classifier\n",
        "    param_grid = {\n",
        "        'clf__kernel': ['linear', 'rbf', 'sigmoid'],\n",
        "        'clf__C': [0.1, 1, 10, 100],\n",
        "        'clf__gamma': ['scale', 'auto', 0.01, 0.1, 1]\n",
        "    }\n",
        "\n",
        "    for aspect in aspects:\n",
        "        print(f\"\\n=== Processing aspect: {aspect} ===\")\n",
        "        # Prepare data for current aspect\n",
        "        X_train, y_train = prepare_data(train_df, aspect)\n",
        "        X_test, y_test = prepare_data(test_df, aspect)\n",
        "\n",
        "        # Encode target labels to numerical values\n",
        "        le = LabelEncoder()\n",
        "        y_train_encoded = le.fit_transform(y_train)\n",
        "        y_test_encoded = le.fit_transform(y_test)\n",
        "\n",
        "        # Build initial pipeline with a placeholder classifier\n",
        "        pipeline = Pipeline([\n",
        "            ('tfidf', TfidfVectorizer(max_features=5000,\n",
        "                                      ngram_range=(1, 2),\n",
        "                                      min_df=5,\n",
        "                                      max_df=0.90,\n",
        "                                      tokenizer=custom_tokenizer)),\n",
        "            ('clf', SVC(random_state=42, class_weight='balanced'))\n",
        "        ])\n",
        "\n",
        "        # 10-fold CV strategy for grid search\n",
        "        cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "        # Ensure there are no missing or empty texts in training set\n",
        "        X_train = X_train.dropna(subset=['clean_text'])\n",
        "        X_train = X_train[X_train['clean_text'].str.strip() != '']\n",
        "\n",
        "        # --- Step 1: Grid Search ---\n",
        "        grid = GridSearchCV(pipeline, param_grid, cv=cv_strategy,\n",
        "                            scoring='balanced_accuracy', n_jobs=-1, return_train_score=True)\n",
        "        grid.fit(X_train['clean_text'], y_train_encoded)\n",
        "        best_params = grid.best_params_\n",
        "        print(f\"Best parameters for aspect '{aspect}': {best_params}\")\n",
        "\n",
        "        # --- Step 2: Build a new pipeline using the best parameters ---\n",
        "        best_pipeline = Pipeline([\n",
        "            ('tfidf', TfidfVectorizer(max_features=5000,\n",
        "                                      ngram_range=(1, 2),\n",
        "                                      min_df=5,\n",
        "                                      max_df=0.90,\n",
        "                                      tokenizer=custom_tokenizer)),\n",
        "            ('clf', SVC(random_state=42,\n",
        "                                             class_weight='balanced',\n",
        "                                             C=best_params['clf__C'],\n",
        "                                             gamma=best_params['clf__gamma'],\n",
        "                                             kernel=best_params['clf__kernel']\n",
        "                                             ))\n",
        "        ])\n",
        "\n",
        "        # --- Step 3: Perform 10-Fold Cross Validation with estimator return ---\n",
        "        cv_results = cross_validate(best_pipeline, X_train['clean_text'], y_train_encoded,\n",
        "                                    cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42),\n",
        "                                    scoring='balanced_accuracy', return_train_score=True,return_estimator=True, n_jobs=-1)\n",
        "        avg_cv_score_test = cv_results['test_score'].mean()\n",
        "        avg_cv_score_train = cv_results['train_score'].mean()\n",
        "        print(avg_cv_score_test)\n",
        "        print(avg_cv_score_train)\n",
        "\n",
        "\n",
        "        print(f\"Average 10-fold CV test Accuracy for aspect '{aspect}': {avg_cv_score_test:.4f}\")\n",
        "        print(f\"Average 10-fold CV train Accuracy for aspect '{aspect}': {avg_cv_score_train:.4f}\")\n",
        "\n",
        "        # --- Step 4: Select the best estimator from the CV folds ---\n",
        "        best_index = np.argmax(cv_results['test_score'])\n",
        "        best_cv_estimator = cv_results['estimator'][best_index]\n",
        "\n",
        "        # Evaluate the selected estimator on the training data (optional)\n",
        "        y_train_pred = best_cv_estimator.predict(X_train['clean_text'])\n",
        "        train_acc = accuracy_score(y_train_encoded, y_train_pred)\n",
        "        print(\"Final Training Accuracy: {:.4f}\".format(train_acc))\n",
        "        train_report = classification_report(y_train_encoded, y_train_pred)\n",
        "        print(\"Final Training Classification Report:\\n\", train_report)\n",
        "\n",
        "        # --- Step 5: Evaluate on Test Data ---\n",
        "        y_test_pred = best_cv_estimator.predict(X_test['clean_text'])\n",
        "        test_acc = accuracy_score(y_test_encoded, y_test_pred)\n",
        "        print(\"Test Accuracy: {:.4f}\".format(test_acc))\n",
        "        test_report = classification_report(y_test_encoded, y_test_pred)\n",
        "        print(\"Test Classification Report:\\n\", test_report)\n",
        "\n",
        "        # Save results for the current aspect\n",
        "        best_models[aspect.lower()] = {\n",
        "            \"model\": best_cv_estimator,\n",
        "            \"label_encoder\": le\n",
        "        }\n",
        "        train_reports[aspect.lower()] = train_report\n",
        "        test_reports[aspect.lower()] = test_report\n",
        "\n",
        "    return best_models, train_reports, test_reports\n"
      ],
      "metadata": {
        "id": "0LP4Q1c_Y6L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aspects = ['Acting', 'direction', 'Music','ovr_sent']"
      ],
      "metadata": {
        "id": "CTP3v4GaaML_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models, train_reports, test_reports = train_final_models_grid_search(train_df,test_df, aspects)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPbDigdYabKu",
        "outputId": "8c894d84-b167-436a-90ef-1bbaf54e1af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing aspect: Acting ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for aspect 'Acting': {'clf__C': 1, 'clf__gamma': 1, 'clf__kernel': 'sigmoid'}\n",
            "0.6288446022269552\n",
            "0.8182376005560892\n",
            "Average 10-fold CV test Accuracy for aspect 'Acting': 0.6288\n",
            "Average 10-fold CV train Accuracy for aspect 'Acting': 0.8182\n",
            "Final Training Accuracy: 0.7673\n",
            "Final Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.89      0.31       131\n",
            "           1       0.94      0.77      0.85      2962\n",
            "           2       0.70      0.75      0.72       848\n",
            "\n",
            "    accuracy                           0.77      3941\n",
            "   macro avg       0.61      0.80      0.63      3941\n",
            "weighted avg       0.87      0.77      0.80      3941\n",
            "\n",
            "Test Accuracy: 0.7241\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.10      0.44      0.16        34\n",
            "           1       0.91      0.75      0.82       746\n",
            "           2       0.63      0.67      0.65       206\n",
            "\n",
            "    accuracy                           0.72       986\n",
            "   macro avg       0.55      0.62      0.54       986\n",
            "weighted avg       0.82      0.72      0.76       986\n",
            "\n",
            "\n",
            "=== Processing aspect: direction ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for aspect 'direction': {'clf__C': 1, 'clf__gamma': 0.1, 'clf__kernel': 'rbf'}\n",
            "0.6511047158939374\n",
            "0.8024938187587607\n",
            "Average 10-fold CV test Accuracy for aspect 'direction': 0.6511\n",
            "Average 10-fold CV train Accuracy for aspect 'direction': 0.8025\n",
            "Final Training Accuracy: 0.7846\n",
            "Final Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.82      0.58       568\n",
            "           1       0.96      0.78      0.86      3128\n",
            "           2       0.55      0.77      0.64       245\n",
            "\n",
            "    accuracy                           0.78      3941\n",
            "   macro avg       0.65      0.79      0.69      3941\n",
            "weighted avg       0.86      0.78      0.81      3941\n",
            "\n",
            "Test Accuracy: 0.7201\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.69      0.44       124\n",
            "           1       0.93      0.74      0.82       804\n",
            "           2       0.36      0.55      0.43        58\n",
            "\n",
            "    accuracy                           0.72       986\n",
            "   macro avg       0.54      0.66      0.57       986\n",
            "weighted avg       0.82      0.72      0.75       986\n",
            "\n",
            "\n",
            "=== Processing aspect: Music ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for aspect 'Music': {'clf__C': 100, 'clf__gamma': 'auto', 'clf__kernel': 'sigmoid'}\n",
            "0.7241765038732287\n",
            "0.8702183734530772\n",
            "Average 10-fold CV test Accuracy for aspect 'Music': 0.7242\n",
            "Average 10-fold CV train Accuracy for aspect 'Music': 0.8702\n",
            "Final Training Accuracy: 0.9457\n",
            "Final Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.92      0.61        89\n",
            "           1       0.98      0.98      0.98      3446\n",
            "           2       0.89      0.69      0.78       406\n",
            "\n",
            "    accuracy                           0.95      3941\n",
            "   macro avg       0.77      0.86      0.79      3941\n",
            "weighted avg       0.96      0.95      0.95      3941\n",
            "\n",
            "Test Accuracy: 0.9432\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.56      0.38        18\n",
            "           1       0.98      0.97      0.98       867\n",
            "           2       0.87      0.74      0.80       101\n",
            "\n",
            "    accuracy                           0.94       986\n",
            "   macro avg       0.71      0.76      0.72       986\n",
            "weighted avg       0.95      0.94      0.95       986\n",
            "\n",
            "\n",
            "=== Processing aspect: ovr_sent ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for aspect 'ovr_sent': {'clf__C': 1, 'clf__gamma': 'scale', 'clf__kernel': 'rbf'}\n",
            "0.6322870910571186\n",
            "0.909353108355892\n",
            "Average 10-fold CV test Accuracy for aspect 'ovr_sent': 0.6323\n",
            "Average 10-fold CV train Accuracy for aspect 'ovr_sent': 0.9094\n",
            "Final Training Accuracy: 0.8754\n",
            "Final Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.90      0.88      1346\n",
            "           1       0.66      0.91      0.77       567\n",
            "           2       0.98      0.85      0.91      2028\n",
            "\n",
            "    accuracy                           0.88      3941\n",
            "   macro avg       0.84      0.89      0.85      3941\n",
            "weighted avg       0.89      0.88      0.88      3941\n",
            "\n",
            "Test Accuracy: 0.6836\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.70      0.69       348\n",
            "           1       0.34      0.47      0.40       139\n",
            "           2       0.84      0.73      0.78       499\n",
            "\n",
            "    accuracy                           0.68       986\n",
            "   macro avg       0.62      0.63      0.62       986\n",
            "weighted avg       0.71      0.68      0.69       986\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(df, aspect_column):\n",
        "    \"\"\"Prepare data for a specific aspect\"\"\"\n",
        "    # Encode text to numerical values if needed\n",
        "    # le = LabelEncoder()\n",
        "    # Changed to return a DataFrame instead of a Series\n",
        "    X = df[['R_clean_text']]\n",
        "    y = df[aspect_column]\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "7rqOBXIqLjkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"Romanised_train_data.csv\")\n",
        "test_df = pd.read_csv(\"Romanised_test_data.csv\")\n",
        "def train_final_models_grid_search(train_df, test_df, aspects):\n",
        "    \"\"\"\n",
        "    For each aspect:\n",
        "    1. Perform grid search on the training data to find the best parameters.\n",
        "    2. Using the best parameters, perform 10-fold cross-validation,\n",
        "       returning both the average accuracy and the list of fold estimators.\n",
        "    3. Select the best estimator from CV (highest test score) and evaluate it on test data.\n",
        "    Returns the best models along with their label encoders and classification reports.\n",
        "    \"\"\"\n",
        "    best_models = {}\n",
        "    train_reports = {}\n",
        "    test_reports = {}\n",
        "\n",
        "    # Parameter grid for the classifier\n",
        "    param_grid = {\n",
        "        'clf__kernel': ['linear', 'rbf', 'sigmoid'],\n",
        "        'clf__C': [0.1, 1, 10, 100],\n",
        "        'clf__gamma': ['scale', 'auto', 0.01, 0.1, 1]\n",
        "    }\n",
        "\n",
        "    for aspect in aspects:\n",
        "        print(f\"\\n=== Processing aspect: {aspect} ===\")\n",
        "        # Prepare data for current aspect\n",
        "        X_train, y_train = prepare_data(train_df, aspect)\n",
        "        X_test, y_test = prepare_data(test_df, aspect)\n",
        "\n",
        "        # Encode target labels to numerical values\n",
        "        le = LabelEncoder()\n",
        "        y_train_encoded = le.fit_transform(y_train)\n",
        "        y_test_encoded = le.fit_transform(y_test)\n",
        "\n",
        "        # Build initial pipeline with a placeholder classifier\n",
        "        pipeline = Pipeline([\n",
        "            ('tfidf', TfidfVectorizer(max_features=5000,\n",
        "                                      ngram_range=(1, 2),\n",
        "                                      min_df=5,\n",
        "                                      max_df=0.90,\n",
        "                                      tokenizer=custom_tokenizer)),\n",
        "            ('clf', SVC(random_state=42, class_weight='balanced'))\n",
        "        ])\n",
        "\n",
        "        # 10-fold CV strategy for grid search\n",
        "        cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "        # Ensure there are no missing or empty texts in training set\n",
        "        X_train = X_train.dropna(subset=['R_clean_text'])\n",
        "        X_train = X_train[X_train['R_clean_text'].str.strip() != '']\n",
        "\n",
        "        # --- Step 1: Grid Search ---\n",
        "        grid = GridSearchCV(pipeline, param_grid, cv=cv_strategy,\n",
        "                            scoring='balanced_accuracy', n_jobs=-1, return_train_score=True)\n",
        "        grid.fit(X_train['R_clean_text'], y_train_encoded)\n",
        "        best_params = grid.best_params_\n",
        "        print(f\"Best parameters for aspect '{aspect}': {best_params}\")\n",
        "\n",
        "        # --- Step 2: Build a new pipeline using the best parameters ---\n",
        "        best_pipeline = Pipeline([\n",
        "            ('tfidf', TfidfVectorizer(max_features=5000,\n",
        "                                      ngram_range=(1, 2),\n",
        "                                      min_df=5,\n",
        "                                      max_df=0.90,\n",
        "                                      tokenizer=custom_tokenizer)),\n",
        "            ('clf', SVC(random_state=42,\n",
        "                                             class_weight='balanced',\n",
        "                                             C=best_params['clf__C'],\n",
        "                                             gamma=best_params['clf__gamma'],\n",
        "                                             kernel=best_params['clf__kernel']\n",
        "                                             ))\n",
        "        ])\n",
        "\n",
        "        # --- Step 3: Perform 10-Fold Cross Validation with estimator return ---\n",
        "        cv_results = cross_validate(best_pipeline, X_train['R_clean_text'], y_train_encoded,\n",
        "                                    cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42),\n",
        "                                    scoring='balanced_accuracy', return_train_score=True,return_estimator=True, n_jobs=-1)\n",
        "        avg_cv_score_test = cv_results['test_score'].mean()\n",
        "        avg_cv_score_train = cv_results['train_score'].mean()\n",
        "        print(avg_cv_score_test)\n",
        "        print(avg_cv_score_train)\n",
        "\n",
        "\n",
        "        print(f\"Average 10-fold CV test Accuracy for aspect '{aspect}': {avg_cv_score_test:.4f}\")\n",
        "        print(f\"Average 10-fold CV train Accuracy for aspect '{aspect}': {avg_cv_score_train:.4f}\")\n",
        "\n",
        "        # --- Step 4: Select the best estimator from the CV folds ---\n",
        "        best_index = np.argmax(cv_results['test_score'])\n",
        "        best_cv_estimator = cv_results['estimator'][best_index]\n",
        "\n",
        "        # Evaluate the selected estimator on the training data (optional)\n",
        "        y_train_pred = best_cv_estimator.predict(X_train['R_clean_text'])\n",
        "        train_acc = accuracy_score(y_train_encoded, y_train_pred)\n",
        "        print(\"Final Training Accuracy: {:.4f}\".format(train_acc))\n",
        "        train_report = classification_report(y_train_encoded, y_train_pred)\n",
        "        print(\"Final Training Classification Report:\\n\", train_report)\n",
        "\n",
        "        # --- Step 5: Evaluate on Test Data ---\n",
        "        y_test_pred = best_cv_estimator.predict(X_test['R_clean_text'])\n",
        "        test_acc = accuracy_score(y_test_encoded, y_test_pred)\n",
        "        print(\"Test Accuracy: {:.4f}\".format(test_acc))\n",
        "        test_report = classification_report(y_test_encoded, y_test_pred)\n",
        "        print(\"Test Classification Report:\\n\", test_report)\n",
        "\n",
        "        # Save results for the current aspect\n",
        "        best_models[aspect.lower()] = {\n",
        "            \"model\": best_cv_estimator,\n",
        "            \"label_encoder\": le\n",
        "        }\n",
        "        train_reports[aspect.lower()] = train_report\n",
        "        test_reports[aspect.lower()] = test_report\n",
        "\n",
        "    return best_models, train_reports, test_reports\n"
      ],
      "metadata": {
        "id": "aG7tiGeeKZvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models, train_reports, test_reports = train_final_models_grid_search(train_df,test_df, aspects)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GgniMGELoPN",
        "outputId": "6c44b769-3b50-43e3-cf3a-ed587ae15de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing aspect: Acting ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for aspect 'Acting': {'clf__C': 1, 'clf__gamma': 1, 'clf__kernel': 'sigmoid'}\n",
            "0.6439033268445034\n",
            "0.8251112211299987\n",
            "Average 10-fold CV test Accuracy for aspect 'Acting': 0.6439\n",
            "Average 10-fold CV train Accuracy for aspect 'Acting': 0.8251\n",
            "Final Training Accuracy: 0.7808\n",
            "Final Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.89      0.34       131\n",
            "           1       0.94      0.78      0.86      2962\n",
            "           2       0.69      0.75      0.72       848\n",
            "\n",
            "    accuracy                           0.78      3941\n",
            "   macro avg       0.61      0.81      0.64      3941\n",
            "weighted avg       0.86      0.78      0.81      3941\n",
            "\n",
            "Test Accuracy: 0.7505\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.12      0.47      0.20        34\n",
            "           1       0.92      0.78      0.84       746\n",
            "           2       0.64      0.67      0.66       206\n",
            "\n",
            "    accuracy                           0.75       986\n",
            "   macro avg       0.56      0.64      0.57       986\n",
            "weighted avg       0.83      0.75      0.78       986\n",
            "\n",
            "\n",
            "=== Processing aspect: direction ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for aspect 'direction': {'clf__C': 100, 'clf__gamma': 'auto', 'clf__kernel': 'rbf'}\n",
            "0.6686530734553268\n",
            "0.8106188945335802\n",
            "Average 10-fold CV test Accuracy for aspect 'direction': 0.6687\n",
            "Average 10-fold CV train Accuracy for aspect 'direction': 0.8106\n",
            "Final Training Accuracy: 0.7896\n",
            "Final Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.84      0.60       568\n",
            "           1       0.96      0.78      0.86      3128\n",
            "           2       0.51      0.80      0.62       245\n",
            "\n",
            "    accuracy                           0.79      3941\n",
            "   macro avg       0.65      0.80      0.69      3941\n",
            "weighted avg       0.86      0.79      0.81      3941\n",
            "\n",
            "Test Accuracy: 0.7059\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.65      0.42       124\n",
            "           1       0.93      0.72      0.81       804\n",
            "           2       0.34      0.62      0.44        58\n",
            "\n",
            "    accuracy                           0.71       986\n",
            "   macro avg       0.53      0.66      0.56       986\n",
            "weighted avg       0.82      0.71      0.74       986\n",
            "\n",
            "\n",
            "=== Processing aspect: Music ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for aspect 'Music': {'clf__C': 1, 'clf__gamma': 1, 'clf__kernel': 'sigmoid'}\n",
            "0.7189723658527452\n",
            "0.8905220069044676\n",
            "Average 10-fold CV test Accuracy for aspect 'Music': 0.7190\n",
            "Average 10-fold CV train Accuracy for aspect 'Music': 0.8905\n",
            "Final Training Accuracy: 0.9137\n",
            "Final Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.92      0.43        89\n",
            "           1       0.99      0.92      0.96      3446\n",
            "           2       0.77      0.82      0.80       406\n",
            "\n",
            "    accuracy                           0.91      3941\n",
            "   macro avg       0.68      0.89      0.73      3941\n",
            "weighted avg       0.95      0.91      0.93      3941\n",
            "\n",
            "Test Accuracy: 0.9057\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      0.56      0.24        18\n",
            "           1       0.99      0.92      0.95       867\n",
            "           2       0.74      0.83      0.79       101\n",
            "\n",
            "    accuracy                           0.91       986\n",
            "   macro avg       0.63      0.77      0.66       986\n",
            "weighted avg       0.95      0.91      0.92       986\n",
            "\n",
            "\n",
            "=== Processing aspect: ovr_sent ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for aspect 'ovr_sent': {'clf__C': 100, 'clf__gamma': 0.01, 'clf__kernel': 'sigmoid'}\n",
            "0.6413702035855965\n",
            "0.7950802730670701\n",
            "Average 10-fold CV test Accuracy for aspect 'ovr_sent': 0.6414\n",
            "Average 10-fold CV train Accuracy for aspect 'ovr_sent': 0.7951\n",
            "Final Training Accuracy: 0.7686\n",
            "Final Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.79      0.79      1346\n",
            "           1       0.47      0.81      0.59       567\n",
            "           2       0.94      0.74      0.83      2028\n",
            "\n",
            "    accuracy                           0.77      3941\n",
            "   macro avg       0.73      0.78      0.74      3941\n",
            "weighted avg       0.82      0.77      0.78      3941\n",
            "\n",
            "Test Accuracy: 0.6613\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.66      0.68       348\n",
            "           1       0.31      0.55      0.39       139\n",
            "           2       0.84      0.69      0.76       499\n",
            "\n",
            "    accuracy                           0.66       986\n",
            "   macro avg       0.62      0.63      0.61       986\n",
            "weighted avg       0.72      0.66      0.68       986\n",
            "\n"
          ]
        }
      ]
    }
  ]
}